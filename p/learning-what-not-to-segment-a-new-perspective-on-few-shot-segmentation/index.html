<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="I read the paper in the first month when I came in MiLab. However, at that time I could not recognize the quality of this method (I usually don&amp;rsquo;t read the experiment carefully). It appeared when I was reading another paper called &amp;ldquo;Holistic Prototype Activation for Few-Shot Segmentation&amp;rdquo;. The HPA performs well but can not beat BAM (although HPA has less parameter to train, obviously). So I decided to read this paper again."><title>Learning What Not to Segment A New Perspective on Few-Shot Segmentation</title><link rel=canonical href=https://SuperCarryDFY.github.io/Blog/p/learning-what-not-to-segment-a-new-perspective-on-few-shot-segmentation/><link rel=stylesheet href=/Blog/scss/style.min.ac77dcf8b111b51da39a92990f431923f210f3876d85798a2125667f96dc33a4.css><meta property="og:title" content="Learning What Not to Segment A New Perspective on Few-Shot Segmentation"><meta property="og:description" content="I read the paper in the first month when I came in MiLab. However, at that time I could not recognize the quality of this method (I usually don&amp;rsquo;t read the experiment carefully). It appeared when I was reading another paper called &amp;ldquo;Holistic Prototype Activation for Few-Shot Segmentation&amp;rdquo;. The HPA performs well but can not beat BAM (although HPA has less parameter to train, obviously). So I decided to read this paper again."><meta property="og:url" content="https://SuperCarryDFY.github.io/Blog/p/learning-what-not-to-segment-a-new-perspective-on-few-shot-segmentation/"><meta property="og:site_name" content="Dai Fengyuan"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="Few-Shot Learning"><meta property="article:tag" content="Segmentation"><meta property="article:published_time" content="2022-08-28T00:00:00+00:00"><meta property="article:modified_time" content="2022-08-28T00:00:00+00:00"><meta property="og:image" content="https://s2.loli.net/2022/08/25/cUieTg3LOa1ZN2k.png"><meta name=twitter:title content="Learning What Not to Segment A New Perspective on Few-Shot Segmentation"><meta name=twitter:description content="I read the paper in the first month when I came in MiLab. However, at that time I could not recognize the quality of this method (I usually don&amp;rsquo;t read the experiment carefully). It appeared when I was reading another paper called &amp;ldquo;Holistic Prototype Activation for Few-Shot Segmentation&amp;rdquo;. The HPA performs well but can not beat BAM (although HPA has less parameter to train, obviously). So I decided to read this paper again."><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://s2.loli.net/2022/08/25/cUieTg3LOa1ZN2k.png"></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/Blog><img src=/Blog/img/avatar_hu9dfbd12334e37b5fd8ca00b30d694e40_207128_300x0_resize_q75_box.jpg width=300 height=300 class=site-logo loading=lazy alt=Avatar></a>
<span class=emoji>ðŸ‘¿</span></figure><div class=site-meta><h1 class=site-name><a href=/Blog>Dai Fengyuan</a></h1><h2 class=site-description>Bachelor at SHU.</h2></div></header><ol class=social-menu><li><a href=https://github.com/SuperCarryDFY/Blog target=_blank title=GitHub><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/Blog/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/Blog/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg><span>Archives</span></a></li><li><a href=/Blog/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li><li><a href=/Blog/about/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><span>About</span></a></li><div class=menu-bottom-section><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></div></ol></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/Blog/p/learning-what-not-to-segment-a-new-perspective-on-few-shot-segmentation/><img src=https://s2.loli.net/2022/08/25/cUieTg3LOa1ZN2k.png loading=lazy alt="Featured image of post Learning What Not to Segment A New Perspective on Few-Shot Segmentation"></a></div><div class=article-details><header class=article-category><a href=/Blog/categories/cv/>CV</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/Blog/p/learning-what-not-to-segment-a-new-perspective-on-few-shot-segmentation/>Learning What Not to Segment A New Perspective on Few-Shot Segmentation</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>Aug 28, 2022</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>3 minute read</time></div></footer></div></header><section class=article-content><p><img src=https://s2.loli.net/2022/08/25/cUieTg3LOa1ZN2k.png loading=lazy alt=image.png></p><p>I read the paper in the first month when I came in MiLab. However, at that time I could not recognize the quality of this method (I usually don&rsquo;t read the experiment carefully). It appeared when I was reading another paper called &ldquo;Holistic Prototype Activation for Few-Shot Segmentation&rdquo;. The HPA performs well but can not beat BAM (although HPA has less parameter to train, obviously). So I decided to read this paper again.</p><h2 id=abstract--introduction>ABSTRACT & INTRODUCTION</h2><p>Previous problem:</p><ul><li>the trained models are biased towards the seen classes instead of being ideally class-agnostic</li></ul><p>Contribution</p><ul><li><p>BAM, i.e., base and the meta has two branches, allowing model to learn what not to segment and what to segmentation, respectively.</p></li><li><p>Design a special loss in order to train two branches suitably.</p></li><li><p>Extend the proposed approach to a more challenging setting, which simultaneously identifies the targets of base and novel classes.</p></li></ul><p>In the following image, (a) is a classical method to address FSS task; (b) is BAM approach; (c) is the extension of BAM</p><p><img src=https://s2.loli.net/2022/08/25/hOT72tJIqimkDKL.png loading=lazy alt=image.png></p><h2 id=method>METHOD</h2><p>They adopt two stage training method, which means they train base learner and meta learner separately.</p><p><img src=https://s2.loli.net/2022/08/25/4KBGJQmrc71nMu2.png loading=lazy alt=image.png></p><h3 id=base-learner>BASE LEARNER</h3><p>Query image goes through four ResNet blocks and becomes intermediate feature maps $f_b^q$. Then the decoder network $D_b$ yields the prediction result. $N_b$ represents the number of base categories.
$$
P_b = softmax(D_b(f_b^q)) \in R^{(1+N_b)\times H\times W}
$$
Loss can be defined as
$$
L_{base} = \frac{1}{n_{bs}}\sum_{i=1}^{n_{bs}}CE(P_{b;i},m^q_{b;i})
$$
It is worth noting that they do not employ the general FSS learning paradigm (update the parameter in each episode). And they train the base learner independently. They explain as follow:</p><blockquote><p>It is unrealistic to additionally build such a large network on the basis of the original few-shot model, which will introduce too many parameters and slow down the inference speed.</p><p>It is unknown whether the base learner can be trained well with the episodic learning paradigm, so a two stage training strategy is eventually adopted.</p></blockquote><p>In the ablation study, it shows that with two stage train, the model can perform better.</p><h3 id=meta-learner>META LEARNER</h3><p>This part is highly resemble similar to CANet, employing &ldquo;expand & concatenate&rdquo; operations. The loss can be described as
$$
L_{meta} = \frac{1}{n_e}\sum_{i=1}^{n_e}BCE(p_{m;i},m_i^q)
$$
, when $n_e$ denotes the number of training episodes in each batch</p><h3 id=ensemble>Ensemble</h3><p>This part is designed to leverage the low-level feature to adjust the coarse predictions which is derived from meta learner.</p><p>Firstly, we calculate the overall indicator $\psi$ for guiding the adjustment process:
$$
A_s = F_{reshape}(f_{low}^s) \in R^{C_1\times N},\
G^s = A_sA^T \in R^{C_1\times C_1}
$$
$G^s$ should be denoted as Gram matrix, BTW.</p><blockquote><p>Gram matrix can be regarded as eccentric covariance matrix between features. Every number in gram matrix describe the relation between every two feature, about which two features appear simultaneously, which two features just offset from each other, etc.</p></blockquote><p>$$
\psi =||G^s - G^q||_F
$$</p><p>$||\ ||_F$ denotes the Frobenius norm of the input metirx.</p><p>After that, the final segmentation pridections $P_f$ can be described as follow:
$$
p_f^0 = F_{ensemble}(F_\psi(p_m^0),p_b^f), \
p_f=p_f^0(+)F_\psi(p_m^1)
$$
where $p_m$,$p_b$ denote the predictions of the meta learner and base learner respectively. The superscript &ldquo;0&rdquo; and &ldquo;1&rdquo; represent the background and foreground respectively. Both $F_Ïˆ$ and $F_{ensemble}$ are 1Ã—1 convolution operations with specific initial parameters.</p><h3 id=loss>LOSS</h3><p>$$
L=L_{final} + \lambda L_{meta} \
L_{final} = \frac{1}{n_e}\sum_{i=1}^{n_e}BCE(p_i^q,m_i^q)
$$</p><p>where $L_{meta}$ is the loss function of the meta learner defined in the meta learner stage.</p><h2 id=experiments>Experiments</h2><p><img src=https://s2.loli.net/2022/08/27/1E4h7VSepL2wHUG.png loading=lazy alt=image.png></p><p><img src=https://s2.loli.net/2022/08/27/JuMlP1aGcUwxI94.png loading=lazy alt=image.png></p></section><footer class=article-footer><section class=article-tags><a href=/Blog/tags/few-shot-learning/>Few-Shot Learning</a>
<a href=/Blog/tags/segmentation/>Segmentation</a></section><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>CC BY-NC-ND</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.css integrity="sha256-J+iAE0sgH8QSz9hpcDxXIftnj65JEZgNhGcgReTTK9s=" crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.js integrity="sha256-InsNdER1b2xUewP+pKCUJpkhiqwHgqiPXDlIk7GzBu4=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/contrib/auto-render.min.js integrity="sha256-y39Mpg7V3D4lhBX4x6O0bUqTV4pSrfgwEfGKfxkOdgI=" crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{renderMathInElement(document.querySelector(`.article-content`),{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/Blog/p/canet-class-agnostic-segmentation-networks-with-iterative-refinement-and-attentive-few-shot-learning/><div class=article-image><img src=https://s2.loli.net/2022/08/16/9DYVUmMyPNJnwkq.png loading=lazy data-key data-hash=https://s2.loli.net/2022/08/16/9DYVUmMyPNJnwkq.png></div><div class=article-details><h2 class=article-title>CANet: Class-Agnostic Segmentation Networks with Iterative Refinement and Attentive Few-Shot Learning</h2></div></a></article><article class=has-image><a href=/Blog/p/holistic-prototype-activation-for-few-shot-segmentation/><div class=article-image><img src=https://s2.loli.net/2022/08/18/wB47rIvCWOyTZVi.png loading=lazy data-key data-hash=https://s2.loli.net/2022/08/18/wB47rIvCWOyTZVi.png></div><div class=article-details><h2 class=article-title>Holistic Prototype Activation for Few-Shot Segmentation</h2></div></a></article><article class=has-image><a href=/Blog/p/prior-guided-feature-enrichment-network-for-few-shot-segmentation/><div class=article-image><img src=https://s2.loli.net/2022/08/16/sO1AU62fiEWBKbQ.png loading=lazy data-key data-hash=https://s2.loli.net/2022/08/16/sO1AU62fiEWBKbQ.png></div><div class=article-details><h2 class=article-title>Prior Guided Feature Enrichment Network for Few-Shot Segmentation</h2></div></a></article><article class=has-image><a href=/Blog/p/few-shot-object-detection-via-feature-reweighting/><div class=article-image><img src=https://s2.loli.net/2022/09/13/hZK19UkL7T3twCr.png loading=lazy data-key data-hash=https://s2.loli.net/2022/09/13/hZK19UkL7T3twCr.png></div><div class=article-details><h2 class=article-title>Few-shot Object Detection via Feature Reweighting</h2></div></a></article><article class=has-image><a href=/Blog/p/one-shot-affordance-detection/><div class=article-image><img src=https://s2.loli.net/2022/08/16/GYdogZcblesFhuk.png loading=lazy data-key data-hash=https://s2.loli.net/2022/08/16/GYdogZcblesFhuk.png></div><div class=article-details><h2 class=article-title>One-Shot Affordance Detection</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2022 -
2023 Dai Fengyuan</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.13.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#abstract--introduction>ABSTRACT & INTRODUCTION</a></li><li><a href=#method>METHOD</a><ol><li><a href=#base-learner>BASE LEARNER</a></li><li><a href=#meta-learner>META LEARNER</a></li><li><a href=#ensemble>Ensemble</a></li><li><a href=#loss>LOSS</a></li></ol></li><li><a href=#experiments>Experiments</a></li></ol></nav></div></section></aside></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/Blog/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>