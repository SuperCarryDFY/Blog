<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="This paper is from ICCV 2019. It addressed detection tasks R-CNN based network. However, it simply uses a shared classifier( mlp, I think) and bbox regressor, which is put forward in R-CNN though, to get predictions. Also, it tries a new form loss function out and gets a relatively large promotion.
ABSTRUCT &amp;amp; INTRODUCTION The model is mainly consist of two modules, i.e.,
a meta feature learner. a light-weight feature reweighting module."><title>Few-shot Object Detection via Feature Reweighting</title><link rel=canonical href=https://SuperCarryDFY.github.io/Blog/p/few-shot-object-detection-via-feature-reweighting/><link rel=stylesheet href=/Blog/scss/style.min.ac77dcf8b111b51da39a92990f431923f210f3876d85798a2125667f96dc33a4.css><meta property="og:title" content="Few-shot Object Detection via Feature Reweighting"><meta property="og:description" content="This paper is from ICCV 2019. It addressed detection tasks R-CNN based network. However, it simply uses a shared classifier( mlp, I think) and bbox regressor, which is put forward in R-CNN though, to get predictions. Also, it tries a new form loss function out and gets a relatively large promotion.
ABSTRUCT &amp;amp; INTRODUCTION The model is mainly consist of two modules, i.e.,
a meta feature learner. a light-weight feature reweighting module."><meta property="og:url" content="https://SuperCarryDFY.github.io/Blog/p/few-shot-object-detection-via-feature-reweighting/"><meta property="og:site_name" content="Fengyuan Dai"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="Detection"><meta property="article:tag" content="Few-Shot Learning"><meta property="article:published_time" content="2022-09-13T00:00:00+00:00"><meta property="article:modified_time" content="2022-09-13T00:00:00+00:00"><meta property="og:image" content="https://s2.loli.net/2022/09/13/hZK19UkL7T3twCr.png"><meta name=twitter:title content="Few-shot Object Detection via Feature Reweighting"><meta name=twitter:description content="This paper is from ICCV 2019. It addressed detection tasks R-CNN based network. However, it simply uses a shared classifier( mlp, I think) and bbox regressor, which is put forward in R-CNN though, to get predictions. Also, it tries a new form loss function out and gets a relatively large promotion.
ABSTRUCT &amp;amp; INTRODUCTION The model is mainly consist of two modules, i.e.,
a meta feature learner. a light-weight feature reweighting module."><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://s2.loli.net/2022/09/13/hZK19UkL7T3twCr.png"></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/Blog><img src=/Blog/img/avatar_hu9dfbd12334e37b5fd8ca00b30d694e40_207128_300x0_resize_q75_box.jpg width=300 height=300 class=site-logo loading=lazy alt=Avatar></a>
<span class=emoji>ðŸ‘¿</span></figure><div class=site-meta><h1 class=site-name><a href=/Blog>Fengyuan Dai</a></h1><h2 class=site-description>Bachelor at SHU.</h2></div></header><ol class=social-menu><li><a href=https://github.com/SuperCarryDFY/Blog target=_blank title=GitHub><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/Blog/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/Blog/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg><span>Archives</span></a></li><li><a href=/Blog/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li><li><a href=/Blog/about/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><span>About</span></a></li><div class=menu-bottom-section><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></div></ol></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/Blog/p/few-shot-object-detection-via-feature-reweighting/><img src=https://s2.loli.net/2022/09/13/hZK19UkL7T3twCr.png loading=lazy alt="Featured image of post Few-shot Object Detection via Feature Reweighting"></a></div><div class=article-details><header class=article-category><a href=/Blog/categories/cv/>CV</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/Blog/p/few-shot-object-detection-via-feature-reweighting/>Few-shot Object Detection via Feature Reweighting</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>Sep 13, 2022</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>3 minute read</time></div></footer></div></header><section class=article-content><p><img src=https://s2.loli.net/2022/09/13/oZqPrCX2h7ixfje.png loading=lazy alt=image-20220913110345915></p><p>This paper is from ICCV 2019. It addressed detection tasks R-CNN based network. However, it simply uses a shared classifier( mlp, I think) and bbox regressor, which is put forward in R-CNN though, to get predictions. Also, it tries a new form loss function out and gets a relatively large promotion.</p><h2 id=abstruct--introduction>ABSTRUCT & INTRODUCTION</h2><p>The model is mainly consist of two modules, i.e.,</p><ul><li>a meta feature learner.</li><li>a light-weight feature reweighting module.</li></ul><p>The training process is corresponding to two-phase learning scheme,</p><ul><li>first learn meta features and good reweighting module from base classes.</li><li>fine-tune the detection model to adapt to novel classes.</li></ul><p>Though it contains two-phase training, it&rsquo;s an end-to-end method.</p><h2 id=method>METHOD</h2><p><img src=https://s2.loli.net/2022/09/13/hZK19UkL7T3twCr.png loading=lazy alt=image-20220913110439796></p><p><strong>Reweighting Module</strong></p><p>This module taking the support examples as input learns to embed support information into reweighting vectors and adjusts the contribution of each meta feature of the query image accordingly for the following detection prediction module.
It is like what is used in BAM. However, in BAM it just uses global max pooling ( or global average pooling, whatever), which is not learnable, to get the prototype vectors. This paper uses a learnable layer to get prototype vectors.
After that, they apply prototype vectors to obtain the class-specific feature Fi for novel class i by F_i = F \times w_i, where \times means channel-wise multiplication.</p><p><strong>Shared Classifier & BBox Regressor</strong></p><p>There aren&rsquo;t any details about Shared Classifier & BBox Regressor module. I simply think this module just being MLP combines BBox Regressor.</p><p><strong>Learning Scheme</strong></p><p>In the first stage, they just feed the model with abundant base images with annotations. In this way, the model can learn to coordinate the two modules in the desired way.</p><p>In the second stage, they fine-tune the model on both base and novel classes. The training procedure is the same as the first phase, except that it takes significantly fewer iterations for the model to converge.</p><p>After two training phases, the model can do a test without a novel class as input (it should not be deemed as a novel class, for it has seen the classes in the second stage) and reweighting module, because it remembers the prototype vectors of all class and just do inference in novel images.</p><h2 id=loss-function>LOSS FUNCTION</h2><p>It is intuitive to use binary cross-entropy as a detection loss function, regressing 1 if the object is the target class and 0 otherwise. However, binary cross-entropy strives to produce balanced positive and negative predictions and could not remove such false predictions.
Instead, they adopt a softmax layer to calibrate the classification scores among different classes. It can be denoted as \hat c_i = \frac{e^{c_i}}{\sum_{j=1}^Ne^{c_j}}. Then, the loss function is belowï¼š
$$
L_c= -\sum_{i=1}^{N}1(Â·,i)log(\hat c_i)
$$</p><p>where 1(Â·, i) is an indicator function for whether the current anchor box really belongs to class i or not.
Finally, the overall loss function is
$$
L_{det} = L_c + L_bbx + L_{obj}
$$</p></section><footer class=article-footer><section class=article-tags><a href=/Blog/tags/detection/>Detection</a>
<a href=/Blog/tags/few-shot-learning/>Few-Shot Learning</a></section><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>CC BY-NC-ND</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.css integrity="sha256-J+iAE0sgH8QSz9hpcDxXIftnj65JEZgNhGcgReTTK9s=" crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.js integrity="sha256-InsNdER1b2xUewP+pKCUJpkhiqwHgqiPXDlIk7GzBu4=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/contrib/auto-render.min.js integrity="sha256-y39Mpg7V3D4lhBX4x6O0bUqTV4pSrfgwEfGKfxkOdgI=" crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{renderMathInElement(document.querySelector(`.article-content`),{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/Blog/p/learning-what-not-to-segment-a-new-perspective-on-few-shot-segmentation/><div class=article-image><img src=https://s2.loli.net/2022/08/25/cUieTg3LOa1ZN2k.png loading=lazy data-key data-hash=https://s2.loli.net/2022/08/25/cUieTg3LOa1ZN2k.png></div><div class=article-details><h2 class=article-title>Learning What Not to Segment A New Perspective on Few-Shot Segmentation</h2></div></a></article><article class=has-image><a href=/Blog/p/canet-class-agnostic-segmentation-networks-with-iterative-refinement-and-attentive-few-shot-learning/><div class=article-image><img src=https://s2.loli.net/2022/08/16/9DYVUmMyPNJnwkq.png loading=lazy data-key data-hash=https://s2.loli.net/2022/08/16/9DYVUmMyPNJnwkq.png></div><div class=article-details><h2 class=article-title>CANet: Class-Agnostic Segmentation Networks with Iterative Refinement and Attentive Few-Shot Learning</h2></div></a></article><article class=has-image><a href=/Blog/p/holistic-prototype-activation-for-few-shot-segmentation/><div class=article-image><img src=https://s2.loli.net/2022/08/18/wB47rIvCWOyTZVi.png loading=lazy data-key data-hash=https://s2.loli.net/2022/08/18/wB47rIvCWOyTZVi.png></div><div class=article-details><h2 class=article-title>Holistic Prototype Activation for Few-Shot Segmentation</h2></div></a></article><article class=has-image><a href=/Blog/p/one-shot-affordance-detection/><div class=article-image><img src=https://s2.loli.net/2022/08/16/GYdogZcblesFhuk.png loading=lazy data-key data-hash=https://s2.loli.net/2022/08/16/GYdogZcblesFhuk.png></div><div class=article-details><h2 class=article-title>One-Shot Affordance Detection</h2></div></a></article><article class=has-image><a href=/Blog/p/prior-guided-feature-enrichment-network-for-few-shot-segmentation/><div class=article-image><img src=https://s2.loli.net/2022/08/16/sO1AU62fiEWBKbQ.png loading=lazy data-key data-hash=https://s2.loli.net/2022/08/16/sO1AU62fiEWBKbQ.png></div><div class=article-details><h2 class=article-title>Prior Guided Feature Enrichment Network for Few-Shot Segmentation</h2></div></a></article></div></div></aside><footer class=site-footer><section class=copyright>&copy;
2022 -
2023 Fengyuan Dai</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.13.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#abstruct--introduction>ABSTRUCT & INTRODUCTION</a></li><li><a href=#method>METHOD</a></li><li><a href=#loss-function>LOSS FUNCTION</a></li></ol></nav></div></section></aside></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/Blog/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>